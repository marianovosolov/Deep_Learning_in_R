---
title: "Movie recommendation system"
author: "Maria Novosolov"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
    theme: united
    highlight: tango
    code_folding: hide
    code_download: true
    font: FiraCode
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(nnet)
library(recommenderlab)
library(lsa)
library(usmap)
library(caret)
library(data.table)
library(recosystem)
norm_rank<- function(Rank){
  (Rank - mean(Rank,na.rm = T))
}
rand_up<- c(50,73,100)
```

Recommendation systems today can be found everywhere, from the movies we watch in platforms such as Netflix and HBO, to music such as Spotify, and e-commerce. In the field of recommendation systems there are several challenges such as how to create recommendations to new users, how to recommend new content to users that don't rate the content they consume, or how to recommend new content to users with diverse tastes. The research into these questions and several others is on going and new ways of improving recommendation systems are constantly emerging.

In this project I will use the MovieLens 100K dataset from keggle to build a recommendation system. I will compare several commonly used models with various performance criteria. Specifically I will focus on 4 different models:

1.  Popularity based recommendation

2.  User-based Collaborative filtering

3.  Item-based Collaborative filtering

4.  Matrix Factorization

# Loading the data

I am loading three datasets that come as part of the MovieLens dataset and the zip code coordinates data downloaded from the internet

#### User-Movie data

A long format table with users, the movies that they ranked, the ranking they gave it, and a timestemp representing the time when the movie was ranked

```{r message=FALSE, warning=FALSE}
movie_user<- read_delim(here::here("ml-100k/u.data"),col_names = F) %>% 
  rename(user.id = X1, movie.id = X2, rank = X3, timeUnix = X4) %>% 
  mutate(timeUnix = as_datetime(timeUnix)) %>% 
  mutate(user.id = as.character(user.id),movie.id = as.character(movie.id)) %>% 
  group_by(user.id) %>% 
  mutate(rank_norm = norm_rank(rank)) %>% 
  ungroup()
summary(movie_user)
```

#### Movie data

A detailed dataset with variable features that describe each movie, such as title, release date, and matrix of garners it belongs to

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
movie_data<- read_delim(here::here("ml-100k/u.item"),col_names = F) %>% 
  rename(movie.id  = X1, movie_title = X2, release_date = X3, video_release_date = X4,
           IMDb_URL = X5, unknown = X6, Action = X7, Adventure = X8, Animation = X9,
           Children = X10, Comedy = X11, Crime = X12, Documentary = X13, Drama = X14, Fantasy = X15, Film_Noir = X16, Horror = X17, Musical = X18, Mystery = X19, Romance = X20, Sci_Fi = X21,
Thriller = X22, War = X23, Western = X24) %>% 
  mutate(movie.id = as.character(movie.id))
movie_data_sub<- movie_data %>% 
  select(movie.id,movie_title)

summary(as_tibble(movie_data))
```

#### User data

A detailed dataset with features that discribe each user, such as age, zip code, and occupation

```{r message=FALSE, warning=FALSE}
user_data<- read_delim(here::here("ml-100k/u.user"),col_names = F) %>% 
  rename(user.id = X1, age = X2, gender = X3, occupation = X4, zip_code = X5) %>% 
  mutate(user.id = as.character(user.id))
summary(user_data)
```

```{r message=FALSE, warning=FALSE}
all_data<- movie_user %>% 
  left_join(user_data,by = "user.id") %>% 
  left_join(movie_data,by = "movie.id") %>% 
  group_by(user.id) %>% 
  mutate(avg_rank = mean(rank,na.rm = T)) %>% 
  ungroup() %>% 
  pivot_longer(cols = 14:32, names_to = "genera",values_to = "value") %>% 
  filter(value != 0) %>% 
  group_by(movie.id) %>% 
  mutate(num_genera = length(unique(genera))) %>%
  ungroup() %>% 
  group_by(user.id) %>% 
  mutate(num_user = mean(num_genera)) %>% 
  ungroup()
```

# Explore the data

#### Find the distribution of how many movies are ranked by users

We can see that on average users rank around 106 movies each with most users ranking only small amount of movies

```{r message=FALSE, warning=FALSE}
movie_user %>% 
  group_by(user.id) %>% 
  summarise(movie.ranked = length(unique(movie.id))) %>% 
  ungroup() %>% 
  ggplot(.,aes(movie.ranked))+
  geom_histogram()+
  theme_bw()+
  geom_vline(xintercept = 106,color = "red")
```

#### Find the distribution of ranks

We can see that 4 is the most common rating that movie get in this dataset

```{r message=FALSE, warning=FALSE}
movie_user %>% 
  ggplot(.,aes(rank))+
  geom_histogram()+
  theme_bw()
```

#### Average movie ratings

```{r message=FALSE, warning=FALSE}
movie_user %>% 
  group_by(movie.id) %>% 
  summarise(avg_rank = mean(rank)) %>% 
  ungroup() %>% 
  select(movie.id,avg_rank) %>% 
  pivot_longer(cols = -movie.id,names_to = "rank_type",values_to = "values") %>% 
  ggplot(.,aes(values))+
  geom_histogram()+
  theme_bw()
```

#### How many movies belong to each genera

```{r message=FALSE, warning=FALSE}
movie_data_long<- movie_data %>% 
  select(1,6:length(.)) %>% 
  pivot_longer(cols = -movie.id, names_to = "genera",values_to = "values") %>% 
  filter(values == 1) %>% 
  group_by(genera) %>% 
  summarise(genera_count = sum(values)) %>% 
  ungroup() 
```

```{r message=FALSE, warning=FALSE}
movie_data_long %>% 
  ggplot(.,aes(reorder(genera,-genera_count), genera_count))+
  geom_col()+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90))+
  xlab("Genera")+
  ylab("Genera count")
```

#### How many movies have one or more genera assigned to them

```{r message=FALSE, warning=FALSE}
movie_data %>% 
  select(1,6:length(.)) %>% 
  pivot_longer(cols = -movie.id, names_to = "genera",values_to = "values") %>% 
  filter(values == 1) %>% 
  group_by(movie.id) %>% 
  summarise(genera_num = sum(values)) %>% 
  ggplot(.,aes(as.character(genera_num)))+
  geom_bar()+
  theme_bw()
```

#### Average movie ratings as a function of the number of users that rated them

```{r message=FALSE, warning=FALSE}
movie_user %>% 
  group_by(movie.id) %>% 
  mutate(avg_rank = mean(rank)) %>% 
  mutate(num_user = length(user.id)) %>% 
  ungroup() %>% 
  select(num_user,avg_rank) %>% 
  distinct() %>% 
  ggplot(.,aes(num_user,avg_rank))+
  geom_point()+
  theme_bw()
```

#### Average movie rating as a function of the average time passed between their release and the average rating

```{r message=FALSE, warning=FALSE}
new_movie_user<- movie_user %>% 
  left_join(movie_data,by = "movie.id") %>% 
  mutate(release_date = dmy(release_date)) %>% 
  mutate(diff_time = as.numeric(difftime(timeUnix,release_date))) %>%
  group_by(movie.id) %>% 
  mutate(min_rank_time = min(diff_time),max_rank_time = max(diff_time)) %>% 
  ungroup() %>% 
  select(user.id,movie.id,rank,rank_norm,diff_time,min_rank_time,max_rank_time)
```

```{r message=FALSE, warning=FALSE}
new_movie_user %>% 
  group_by(movie.id) %>% 
  mutate(avg_rank = mean(rank),avg_diff_time = mean(diff_time,na.rm = T)) %>% 
  ungroup() %>% 
  ggplot(.,aes(log10(avg_diff_time),avg_rank))+
  geom_point()+
  theme_bw()+
  geom_smooth(method = "lm")
```

#### Test is this correlation is significant

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
new_movie_user %>% 
  group_by(movie.id) %>% 
  mutate(avg_rank = mean(rank),avg_diff_time = mean(diff_time,na.rm = T)) %>% 
  ungroup() %>% 
  lm(avg_rank~log10(avg_diff_time),data = .) %>% 
  summary() %>% 
  broom::tidy() %>% 
  knitr::kable()
```

**This model explains 14% of the variation in the data**

#### Average rating based on genera

```{r}
movie_data %>% 
  select(1,6:length(.)) %>% 
  pivot_longer(cols = -movie.id, names_to = "genera",values_to = "values") %>% 
  filter(values == 1) %>% 
  group_by(genera) %>% 
  mutate(genera_count = sum(values)) %>% 
  ungroup()  %>% 
  left_join(movie_user, by = "movie.id") %>% 
  group_by(genera) %>% 
  mutate(avg_rank = mean(rank)) %>%
  select(genera,avg_rank) %>% 
  distinct() %>% 
  ggplot(.,aes(reorder(genera,-avg_rank),avg_rank))+
  geom_col()+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90))+
  xlab("Genera")+
  ylab("Average rating")
```

#### Average rating as a function of how many genera there are

```{r}
movie_data %>% 
  select(1,6:length(.)) %>% 
  pivot_longer(cols = -movie.id, names_to = "genera",values_to = "values") %>% 
  filter(values == 1) %>% 
  group_by(movie.id) %>% 
  mutate(genera_num = sum(values))%>% 
  ungroup()  %>% 
  left_join(movie_user, by = "movie.id") %>% 
  group_by(movie.id) %>% 
  mutate(avg_rank = mean(rank)) %>% 
  ungroup() %>% 
  select(genera_num,avg_rank) %>% 
  distinct() %>% 
  ggplot(.,aes(as.character(genera_num),avg_rank))+
  geom_boxplot()+
  theme_bw()+
  labs(x = "Number of genera for a movie", y = "Average rating")
```

# Building the recommendation system

First do some data manipulation to convert the data type into a type that works with the package `recommenderlab`. I decided to compare the models performance with using the true ranks and the binary of like-only matrix. The package does not have an option to caculate all the parameters that allow to compare the performance for the binary data so I will focus on the true ranks.

```{r message=FALSE, warning=FALSE}
movie_ranke_m<- movie_user %>% 
  select(user.id,movie.id,rank) %>% 
  pivot_wider(id_cols = "user.id",names_from = "movie.id",values_from = "rank",values_fill = NA) %>% 
  select(-user.id) %>% 
  as.matrix()
#Convert rating matrix into a recommenderlab sparse matrix
user_id<- movie_user %>% 
  select(user.id,movie.id,rank) %>% 
  pivot_wider(id_cols = "user.id",names_from = "movie.id",values_from = "rank",values_fill = NA) %>% 
  select(user.id) %>% 
  as.vector()
rownames(movie_ranke_m)<- user_id$user.id
ratingmat<- movie_ranke_m
ratingmat <- as(ratingmat, "realRatingMatrix")

```

The data has some users that invested very little in ranking the items and some items that have very little ranking. This type of data is not very informative and does not give us enough power to use for prediction.

```{r}
paste0("Minimum rankings a user gave: ",min(rowCounts(ratingmat)))
paste0("Minimum rankings an item got: ", min(colCounts(ratingmat)))
```

We can see that the a user with the minimum rankings is 20 but there is at least one item that got a rating from only one user. This is not very informative. Thus I will remove any users and items that have less than 50 ranking. This is a qualitative decision and it might be worth to play around with this number to see whether some more data can be retained by decreasing the minimum number of rankings to consider.

```{r}
#for true rankings
ratings_movies <- ratingmat[rowCounts(ratingmat) > 50,
                            colCounts(ratingmat) > 50]
```

After converting the data into the proper data for the package and binarizing it I will split it into train and test data. The data that comes from kaggle has a split train and test data that is a 80/20 split but as it is a random split I decided it will be easier to split the subsetted data using the functions from the `recommenderlab` package.

```{r}
set.seed(182)
eval_split<- evaluationScheme(ratings_movies, method="split", train=0.8,given=10, goodRating = 3)

```

### 1. Popularity based recommender

Tthis type of model ranks the most popular movies in the dataset and recommends them to the users. This is a good method to recommend content to new users that you have no knowledge about their preferences. I will use this model as a benchmark. I expect it to perform poorly because

```{r}
recc_model_popular <- Recommender(data = getData(eval_split, "train"), 
                               method = "RANDOM")
```

```{r}
recc_predicted_popular <- predict(object = recc_model_popular, 
                          newdata = getData(eval_split, "known"),type = "ratingMatrix")
recc_predicted_popular_n <- predict(object = recc_model_popular, 
                          newdata = getData(eval_split, "known"))
```

Lets check what the model recommended. I'll extract three random users and check the top 5 movies that the model recommended.

```{r message=FALSE, warning=FALSE}
predict_p<- bind_rows(recc_predicted_popular_n@items)


rand_user_data_p<-predict_p[,rand_up]


rand_user_data_p<- rand_user_data_p %>% 
  rename(user_49 = `49`,user_72 = `72`,user_99 = `99`)

rand_user_data_p %>% 
  reshape2::melt() %>% 
  mutate(value = as.character(value)) %>% 
  left_join(movie_data_sub,by = c("value" = "movie.id")) %>% 
  mutate(id.col = rep(1:10,3)) %>% 
  pivot_wider(id_cols = "id.col",names_from = "variable",values_from = "movie_title") %>% 
  select(-id.col) %>% 
  knitr::kable()
```

```{r eval=FALSE, include=FALSE}
eval_accuracy_p<- rbind(
Popularity = calcPredictionAccuracy(recc_predicted_popular, getData(eval_split, "unknown"),goodRating = 3,given=10))
knitr::kable(eval_accuracy_p)
```

```{r}
eval_accuracy_p_u<- calcPredictionAccuracy(recc_predicted_popular, getData(eval_split, "unknown"),goodRating = 3,given=10,byUser = T)
P_RMSE<- data.frame(P_RMSE = eval_accuracy_p_u[,"RMSE"],user.id = rownames(eval_accuracy_p_u))
```

### 2. User-based recommender

This type of model utilizes the recommendations from similar users to recommend products to a user. This is a "word-to-moth" type of approach. It first finds similar users and then finds the products these users liked to recommend them to users that didn't rate these product. This is a good method to use when you have good amount of rating data from many users. The big drawback of this method is that it is is not scaleble because you need to rerun the similarity matrix everytime you get new information.

```{r}
recc_model_user <- Recommender(data = getData(eval_split, "train"), 
                               method = "UBCF")
```

```{r}
recc_predicted_user <- predict(object = recc_model_user, 
                               newdata = getData(eval_split, "known"),type = "ratingMatrix")
recc_predicted_user_n <- predict(object = recc_model_user, 
                               newdata = getData(eval_split, "known"))
```

Lets check what the model recommended. I'll extract three random users and check the top 5 movies that the model recommended.

```{r message=FALSE, warning=FALSE}
predict_u<- bind_rows(recc_predicted_user_n@items)


rand_user_data_u<-predict_u[,rand_up]


rand_user_data_u<- rand_user_data_u %>% 
  rename(user_49 = `49`,user_72 = `72`,user_99 = `99`)

rand_user_data_u %>% 
  reshape2::melt() %>% 
  mutate(value = as.character(value)) %>% 
  left_join(movie_data_sub,by = c("value" = "movie.id")) %>% 
  mutate(id.col = rep(1:10,3)) %>% 
  pivot_wider(id_cols = "id.col",names_from = "variable",values_from = "movie_title") %>% 
  select(-id.col) %>% 
  knitr::kable()
```

```{r eval=FALSE, include=FALSE}
eval_accuracy_UB<- rbind(
  User_based = calcPredictionAccuracy(recc_predicted_user, getData(eval_split, "unknown"),goodRating = 3,given=10)
)

knitr::kable(eval_accuracy_UB)
```

```{r}
eval_accuracy_UB_u<- calcPredictionAccuracy(recc_predicted_user, getData(eval_split, "unknown"),goodRating = 3,given=10,byUser = T)
UB_RMSE<- data.frame(UB_RMSE = eval_accuracy_UB_u[,"RMSE"],user.id = rownames(eval_accuracy_UB_u))
```

### 3. Item-based recommender

This is similar to the user-based approach but here assumes that users would like similar items. It first finds similar items and then recommends to the users items it didn't rate yet. This method is again not scaleble so is only useful if you have a managble data size, which is not the case in many companies. Another drawback of this method is that it will rarely help the user to explore new products outside of the scope of their previous ranking.

```{r}
recc_model_item <- Recommender(data = getData(eval_split, "train"), 
                                  method = "IBCF")
```

```{r}
recc_predicted_item <- predict(object = recc_model_item, 
                                  newdata = getData(eval_split, "known"),type = "ratingMatrix")
recc_predicted_item_n <- predict(object = recc_model_item, 
                                  newdata = getData(eval_split, "known"))
```

Lets check what the model recommended. I'll extract three random users and check the top 5 movies that the model recommended.

```{r message=FALSE, warning=FALSE}
predict_i<- bind_rows(recc_predicted_item_n@items)


rand_user_data_i<-predict_i[,rand_up]


rand_user_data_i<- rand_user_data_i %>% 
  rename(user_49 = `49`,user_72 = `72`,user_99 = `99`)

rand_user_data_i %>% 
  reshape2::melt() %>% 
  mutate(value = as.character(value)) %>% 
  left_join(movie_data_sub,by = c("value" = "movie.id")) %>% 
  mutate(id.col = rep(1:10,3)) %>% 
  pivot_wider(id_cols = "id.col",names_from = "variable",values_from = "movie_title") %>% 
  select(-id.col) %>% 
  knitr::kable()
```

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
eval_accuracy_IB<- rbind(
  Item_based = calcPredictionAccuracy(recc_predicted_item, getData(eval_split, "unknown"),goodRating = 3,given=10)
)
knitr::kable(eval_accuracy_IB)
```

```{r message=FALSE, warning=FALSE}
eval_accuracy_IB_u<- calcPredictionAccuracy(recc_predicted_item, getData(eval_split, "unknown"),goodRating = 3,given=10,byUser = T)
IB_RMSE<- data.frame(IB_RMSE = eval_accuracy_IB_u[,"RMSE"],user.id = rownames(eval_accuracy_IB_u))
```

### 4. Matrix Factorization

The idea behind matrix factorization is to choose several latent factors (rule of thumb is 5 but can be more or less and can be optimized). These factors represent the relationship between the users and movies. Taking the dot product for each user and movie vectors will give us the ranking at the cell that represents that user-movie combination. We start with random number and calculate the predictions of the rating. The first predictions will be bad but we can then optimize these latent factors using gradient decent or a different optimization technique and use them to predict which other movies the user will like. We calculate the Squared Error Loss between the random prediction and the real data and use it as the loss function then we optimize it to find the lowest RSME.

```{r message=FALSE, warning=FALSE}
train_data<- getData(eval_split, "train")
train_data_long<- as(train_data,"matrix") %>% 
  as.data.frame() %>% 
  mutate(user.id = rownames(.)) %>% 
  pivot_longer(cols = -user.id,names_to = "movie.id",values_to = "rank") %>% 
  na.omit()
# now I will convert it to the recosystem data type
train_data_eco<- with(train_data_long, data_memory(user_index = user.id, 
                                              item_index = movie.id, 
                                              rating     = rank))

# Create the model object
r <-  recosystem::Reco()

# optimize the parameters
opts <- r$tune(train_data_eco, opts = list(dim = c(10, 20, 30), 
                                       lrate = c(0.1, 0.2),
                                       costp_l2 = c(0.01, 0.1), 
                                       costq_l2 = c(0.01, 0.1),
                                       nthread  = 4, niter = 10))


# Now lets add those into the model wrap in recommandlab
recc_model_MF <- Recommender(data = getData(eval_split, "train"), 
                              method = "LIBMF",param = list(costp_l2 = opts$min$costp_l2,costq_l2 = opts$min$costq_l2,dim = opts$min$dim))

# now lets predict and see how it performs
recc_predicted_MF <- predict(object = recc_model_MF, 
                              newdata = getData(eval_split, "known"),type = "ratingMatrix")
recc_predicted_MF_n <- predict(object = recc_model_MF, 
                              newdata = getData(eval_split, "known"))
```

Lets check what the model recommended. I'll extract three random users and check the top 5 movies that the model recommended.

```{r message=FALSE, warning=FALSE}
predict_mf<- bind_rows(recc_predicted_MF_n@items)


rand_user_data_mf<-predict_mf[,rand_up]


rand_user_data_mf<- rand_user_data_mf %>% 
  rename(user_49 = `49`,user_72 = `72`,user_99 = `99`)

rand_user_data_mf %>% 
  reshape2::melt() %>% 
  mutate(value = as.character(value)) %>% 
  left_join(movie_data_sub,by = c("value" = "movie.id")) %>% 
  mutate(id.col = rep(1:10,3)) %>% 
  pivot_wider(id_cols = "id.col",names_from = "variable",values_from = "movie_title") %>% 
  select(-id.col) %>% 
  knitr::kable()
```

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
eval_accuracy_MF<- rbind(
  Matrix_factorization = calcPredictionAccuracy(recc_predicted_MF, getData(eval_split, "unknown"),goodRating = 3,given=10)
)
knitr::kable(eval_accuracy_MF)
```

```{r message=FALSE, warning=FALSE}
eval_accuracy_MF_u<- calcPredictionAccuracy(recc_predicted_MF, getData(eval_split, "unknown"),goodRating = 3,given=10,byUser = T)
MF_RMSE<- data.frame(MF_RMSE = eval_accuracy_MF_u[,"RMSE"],user.id = rownames(eval_accuracy_MF_u))

```

Let's summarize these parameters to see which model performed best

```{r message=FALSE, warning=FALSE}
eval_accuracy<- rbind(
  Popularity = calcPredictionAccuracy(recc_predicted_popular, getData(eval_split, "unknown"),goodRating = 3,given=10),
  User_based = calcPredictionAccuracy(recc_predicted_user, getData(eval_split, "unknown"),goodRating = 3,given=10),
  Item_based = calcPredictionAccuracy(recc_predicted_item, getData(eval_split, "unknown"),goodRating = 3,given=10),
  Matrix_factorization = calcPredictionAccuracy(recc_predicted_MF, getData(eval_split, "unknown"),goodRating = 3,given=10)
)
knitr::kable(eval_accuracy)
```

```{r message=FALSE, warning=FALSE}
all_RMSE <- data.frame(cbind(user.id = P_RMSE$user.id,
                             P_RMSE = P_RMSE$P_RMSE,
                             UB_RMSE = UB_RMSE$UB_RMSE,
                             IB_RMSE = IB_RMSE$IB_RMSE,
                             MF_RMSE = MF_RMSE$MF_RMSE))
all_RMSE %>% 
  pivot_longer(cols = -user.id,names_to = "model",values_to = "RMSE") %>% 
  mutate(RMSE = as.numeric(RMSE),model = factor(model, levels = c("P_RMSE","UB_RMSE","IB_RMSE","MF_RMSE"))) %>% 
  ggplot(.,aes(model,RMSE,fill = model))+
  geom_boxplot()+
  theme_bw()+
  scale_fill_manual(values = c("#2a9d8f","#e9c46a","#f4a261","#e76f51"))
```

We can see that the matrix factorization method did the best job at generating accurate predictions of the ranking the users would give the movies. However accuracy is not the only thing we are interested in. We can look a bit closer into some other parameters that will give us an understanding about how well the models did. Here I will add the binary data and see whether it performs better or the same

# Model Performance

We can also calculate the the error rate parameters for the true data. We want to see the lowest number. For example the Netflix recommendation system had an RMSE of 0.95 and the Netflix prize winners managed to get to RMSE of 0.85

Additional parameters that are interesting to explore:

**Recall** - How many items were recommended correctly from the total useful recommendations

**Precision - How many items were recommended correctly from the total recommended items**

**Accuracy** -How many cells were correctly predicted from the total possible recommendations (True positives + True Negatives/all data)

Recall and precision are conflicting parameters so it would be useful to find the sweet spot on where they both perform best. We can do that by calculating the F-measure which is (2/(1/Precision+1/Recall))

```{r message=FALSE, warning=FALSE}
eval_accuracy_n<- rbind(
  Popularity = calcPredictionAccuracy(recc_predicted_popular_n, getData(eval_split, "unknown"),goodRating = 3,given=10),
  User_based = calcPredictionAccuracy(recc_predicted_user_n, getData(eval_split, "unknown"),goodRating = 3,given=10),
  Item_based = calcPredictionAccuracy(recc_predicted_item_n, getData(eval_split, "unknown"),goodRating = 3,given=10),
  Matrix_factorization = calcPredictionAccuracy(recc_predicted_MF_n, getData(eval_split, "unknown"),goodRating = 3,given=10)
)
eval_accuracy_n %>% 
  as.data.frame() %>% 
  mutate(accuracy = (TP+TN)/(TP+TN+FP+FN)) %>% 
  mutate(F_measure = (2/(1/precision+1/recall))) %>% 
  mutate(model_type = rownames(.)) %>% 
  select(model_type, accuracy,recall,precision,F_measure) %>% 
  knitr::kable()
```

```{r message=FALSE, warning=FALSE}
eval_accuracy_n %>% 
  as.data.frame() %>% 
  mutate(accuracy = (TP+TN)/(TP+TN+FP+FN)) %>% 
  mutate(F_measure = (2/(1/precision+1/recall))) %>%
  mutate(model_type = rownames(.)) %>% 
  select(recall,precision,F_measure,model_type) %>% 
  pivot_longer(cols = -model_type, names_to = "parameter",values_to = "values") %>% 
  ggplot(.,aes(parameter,model_type,fill = values))+
  geom_tile()+
  scale_fill_distiller(direction = 1)+
  theme_minimal()
  
```

Let's look at the distribution of these parameters by user

```{r fig.height=10, fig.width=10, message=FALSE, warning=FALSE}
Popularity_nu = as.data.frame(calcPredictionAccuracy(recc_predicted_popular_n, getData(eval_split, "unknown"),goodRating = 3,given=10,byUser = T))
Popularity_nu$model_type <- "Popularity"
User_based_nu = as.data.frame(calcPredictionAccuracy(recc_predicted_user_n, getData(eval_split, "unknown"),goodRating = 3,given=10,byUser = T))
User_based_nu$model_type<- "User_based"
Item_based_nu = as.data.frame(calcPredictionAccuracy(recc_predicted_item_n, getData(eval_split, "unknown"),goodRating = 3,given=10,byUser = T))
Item_based_nu$model_type<- "Item_based"
Matrix_factorization_nu = as.data.frame(calcPredictionAccuracy(recc_predicted_MF_n, getData(eval_split, "unknown"),goodRating = 3,given=10,byUser = T))
Matrix_factorization_nu$model_type<- "Matrix_factorization"

eval_accuracy_nu<- rbind(Popularity_nu,User_based_nu,Item_based_nu,Matrix_factorization_nu)
eval_accuracy_nu %>% 
  as_tibble() %>% 
  group_by(model_type) %>% 
  mutate(accuracy = (TP+TN)/(TP+TN+FP+FN)) %>% 
  mutate(F_measure = (2/(1/precision+1/recall))) %>%
  ungroup() %>% 
  select(recall,precision,accuracy,F_measure,model_type) %>% 
  pivot_longer(cols = -model_type, names_to = "parameter",values_to = "values") %>% 
  mutate(model_type = factor(model_type, levels = c("Popularity","User_based","Item_based","Matrix_factorization"))) %>% 
  ggplot(.,aes(model_type,values,fill = model_type))+
  geom_boxplot()+
  theme_bw()+
  scale_fill_manual(values = c("#2a9d8f","#e9c46a","#f4a261","#e76f51"))+
  facet_wrap(.~parameter,scales = "free_y")+
  theme(legend.position = "bottom")+
  xlab("Model type")
```
